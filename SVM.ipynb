{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengaktifkan visualisasi inline matplotlib di notebook\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "# Mengimpor library yang diperlukan\n",
    "import pandas as pd              # Untuk manipulasi data berbentuk tabel\n",
    "import numpy as np               # Untuk komputasi numerik\n",
    "from textblob import TextBlob    # Untuk pemrosesan teks dan analisis sentimen\n",
    "from sklearn.svm import SVC      # Support Vector Classification, algoritma untuk klasifikasi\n",
    "import seaborn as sns            # Untuk visualisasi data yang lebih menarik\n",
    "sns.set_context('notebook')\n",
    "sns.set_style('white')\n",
    "import nltk                      # Natural Language Toolkit untuk pemrosesan bahasa alami\n",
    "from nltk.corpus import stopwords # Untuk menghilangkan kata-kata umum yang tidak bermakna\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer  # Untuk mengubah teks menjadi vektor fitur\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV  # Untuk pembagian data dan optimasi parameter\n",
    "from sklearn.metrics import classification_report  # Untuk evaluasi model\n",
    "from sklearn.pipeline import Pipeline  # Untuk menggabungkan beberapa langkah pemrosesan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>liked</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>India is developing countries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The Da Vinci Code book is just awesome.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>this was the first clive cussler i've ever rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>i liked the Da Vinci Code a lot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>i liked the Da Vinci Code a lot.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   liked                                               text\n",
       "0      1                      India is developing countries\n",
       "1      1            The Da Vinci Code book is just awesome.\n",
       "2      1  this was the first clive cussler i've ever rea...\n",
       "3      1                   i liked the Da Vinci Code a lot.\n",
       "4      1                   i liked the Da Vinci Code a lot."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Membaca data dari file training.txt dengan pemisah tab\n",
    "# Kolom diberi nama 'liked' dan 'text', dengan 'liked' sebagai label sentimen\n",
    "df = pd.read_csv(\"training.txt\", sep=\"\\t\", names=['liked', 'text'], encoding=\"utf-8\")\n",
    "df.head()  # Menampilkan 5 data pertama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6931\n"
     ]
    }
   ],
   "source": [
    "# Menampilkan jumlah total data dalam dataset\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liked</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2975</td>\n",
       "      <td>559</td>\n",
       "      <td>I hate Harry Potter.</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3956</td>\n",
       "      <td>744</td>\n",
       "      <td>I love Harry Potter.</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       text                                  \n",
       "      count unique                   top freq\n",
       "liked                                        \n",
       "0      2975    559  I hate Harry Potter.   85\n",
       "1      3956    744  I love Harry Potter.  167"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menampilkan statistik deskriptif berdasarkan kategori 'liked'\n",
    "df.groupby('liked').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk mengekstrak token (kata-kata) dari teks\n",
    "def tokens(review):\n",
    "    return TextBlob(review).words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   [India, is, developing, countries]\n",
       "1      [The, Da, Vinci, Code, book, is, just, awesome]\n",
       "2    [this, was, the, first, clive, cussler, i, 've...\n",
       "3             [i, liked, the, Da, Vinci, Code, a, lot]\n",
       "4             [i, liked, the, Da, Vinci, Code, a, lot]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menerapkan fungsi tokens pada 5 data pertama\n",
    "df.head().text.apply(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ready', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('not', 'RB'),\n",
       " ('a', 'DT'),\n",
       " ('good', 'JJ'),\n",
       " ('movie', 'NN')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contoh penggunaan TextBlob untuk POS tagging (menandai jenis kata)\n",
    "TextBlob(\"ready was not a good movie\").tags\n",
    "#nltk.help.upenn_tagset('JJ')  # Untuk melihat penjelasan tag JJ (adjective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     [india, is, developing, country]\n",
       "1      [the, da, vinci, code, book, is, just, awesome]\n",
       "2    [this, wa, the, first, clive, cussler, i, 've,...\n",
       "3             [i, liked, the, da, vinci, code, a, lot]\n",
       "4             [i, liked, the, da, vinci, code, a, lot]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fungsi untuk mengubah kata-kata ke bentuk dasar (lemmatization)\n",
    "def to_lemmas(review):\n",
    "    wordss = TextBlob(review.lower()).words\n",
    "    # for each word, take its \"base form\" = lemma\n",
    "    return [word.lemma for word in wordss]\n",
    "\n",
    "# Menerapkan fungsi to_lemmas pada 5 data pertama\n",
    "df.text.head().apply(to_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'octopus'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contoh lemmatization menggunakan WordNetLemmatizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lmtzr = WordNetLemmatizer()\n",
    "lmtzr.lemmatize('octopi')  # Mengubah bentuk jamak 'octopi' menjadi bentuk tunggal 'octopus'\n",
    "#nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert data ke vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2114\n"
     ]
    }
   ],
   "source": [
    "# Membuat transformer Bag of Words dan melatihnya dengan data teks\n",
    "bow_transformer = CountVectorizer(analyzer=to_lemmas).fit(df['text'])\n",
    "# Menampilkan jumlah kata unik dalam kosakata\n",
    "print(len(bow_transformer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i liked the Da Vinci Code a lot.\n"
     ]
    }
   ],
   "source": [
    "# Mengambil teks ulasan ke-4 (indeks 3)\n",
    "review1 = df['text'][3]\n",
    "print(review1)\n",
    "#to check 3rd document/review in collection/database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 42)\t1\n",
      "  (0, 369)\t1\n",
      "  (0, 458)\t1\n",
      "  (0, 950)\t1\n",
      "  (0, 1123)\t1\n",
      "  (0, 1152)\t1\n",
      "  (0, 1838)\t1\n",
      "  (0, 1977)\t1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 2114)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mengubah teks menjadi representasi Bag of Words (vektor fitur)\n",
    "bow = bow_transformer.transform([review1])\n",
    "print(bow)\n",
    "bow.shape  # Menampilkan dimensi vektor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code-other\n"
     ]
    }
   ],
   "source": [
    "# Melihat kata yang ada di indeks 372 dari kosakata\n",
    "print(bow_transformer.get_feature_names_out()[372])\n",
    "#to check 372nd word in collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparse matrix shape: (6931, 2114)\n",
      "number of non-zeros: 71297\n",
      "sparsity: 0.49%\n"
     ]
    }
   ],
   "source": [
    "# Mengubah seluruh dataset teks menjadi representasi Bag of Words\n",
    "review_bow = bow_transformer.transform(df['text'])\n",
    "print('sparse matrix shape:', review_bow.shape)\n",
    "print('number of non-zeros:', review_bow.nnz)  # Jumlah nilai non-nol dalam matriks\n",
    "print('sparsity: %.2f%%' % (100.0 * review_bow.nnz / (review_bow.shape[0] * review_bow.shape[1])))  # Persentase sparsitas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tf-idf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6931, 2114)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mengubah representasi Bag of Words menjadi TF-IDF\n",
    "# TF-IDF memberikan bobot lebih tinggi pada kata yang unik dan jarang muncul\n",
    "tfidf_transformer = TfidfTransformer().fit(review_bow)\n",
    "review_tfidf = tfidf_transformer.transform(review_bow)\n",
    "review_tfidf.shape  # Menampilkan dimensi matriks TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5544 1387 5544 1387\n"
     ]
    }
   ],
   "source": [
    "# Membagi data menjadi data latih (80%) dan data uji (20%)\n",
    "text_train, text_test, liked_train, liked_test = train_test_split(df['text'], df['liked'], test_size=0.2)\n",
    "print(len(text_train), len(text_test), len(text_train), len(text_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat pipeline pemrosesan yang terdiri dari:\n",
    "# 1. CountVectorizer (Bag of Words)\n",
    "# 2. TfidfTransformer (TF-IDF)\n",
    "# 3. SVC (Support Vector Classification)\n",
    "pipeline_svm = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=to_lemmas)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', SVC()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mendefinisikan parameter yang akan dieksplorasi untuk optimasi model\n",
    "param_svm = [\n",
    "    {'classifier__C': [1, 10, 100, 1000], 'classifier__kernel': ['linear']},\n",
    "    {'classifier__C': [1, 10, 100, 1000], 'classifier__gamma': [0.001, 0.0001], 'classifier__kernel': ['rbf']},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melakukan Grid Search untuk menemukan parameter terbaik\n",
    "grid_svm = GridSearchCV(\n",
    "    pipeline_svm,  # object used to fit the data\n",
    "    param_grid=param_svm,\n",
    "    refit=True,  # fit using all data, on the best detected classifier\n",
    "    n_jobs=-1,  # number of cores to use for parallelization; -1 for \"all cores\" i.e. to run on all CPUs\n",
    "    scoring='accuracy',  # optimizing parameter\n",
    "    cv=StratifiedKFold(n_splits=5),  # 5-fold cross validation dengan stratifikasi\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.08 s, sys: 242 ms, total: 1.32 s\n",
      "Wall time: 18.6 s\n",
      "{'mean_fit_time': array([5.58978715, 5.48989902, 3.09671469, 1.2876081 , 2.84231939,\n",
      "       2.80967612, 2.29692588, 2.7356513 , 1.35873237, 2.24772377,\n",
      "       1.32600689, 1.13920345]), 'std_fit_time': array([0.24242936, 0.14841841, 2.25307242, 0.07066413, 0.17707761,\n",
      "       0.24781218, 0.07171164, 0.03329448, 0.06873422, 0.05550277,\n",
      "       0.050977  , 0.23360295]), 'mean_score_time': array([0.31283374, 0.30499916, 0.32684546, 0.31812096, 0.57820616,\n",
      "       0.59130044, 0.53040872, 0.59727974, 0.34178147, 0.49111223,\n",
      "       0.32925968, 0.23081779]), 'std_score_time': array([0.01982824, 0.01719803, 0.02459215, 0.03880559, 0.03221084,\n",
      "       0.01272352, 0.03966375, 0.02234449, 0.01139661, 0.01909675,\n",
      "       0.01538095, 0.05407407]), 'param_classifier__C': masked_array(data=[1, 10, 100, 1000, 1, 1, 10, 10, 100, 100, 1000, 1000],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value=999999), 'param_classifier__kernel': masked_array(data=['linear', 'linear', 'linear', 'linear', 'rbf', 'rbf',\n",
      "                   'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_classifier__gamma': masked_array(data=[--, --, --, --, 0.001, 0.0001, 0.001, 0.0001, 0.001,\n",
      "                   0.0001, 0.001, 0.0001],\n",
      "             mask=[ True,  True,  True,  True, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value=1e+20), 'params': [{'classifier__C': 1, 'classifier__kernel': 'linear'}, {'classifier__C': 10, 'classifier__kernel': 'linear'}, {'classifier__C': 100, 'classifier__kernel': 'linear'}, {'classifier__C': 1000, 'classifier__kernel': 'linear'}, {'classifier__C': 1, 'classifier__gamma': 0.001, 'classifier__kernel': 'rbf'}, {'classifier__C': 1, 'classifier__gamma': 0.0001, 'classifier__kernel': 'rbf'}, {'classifier__C': 10, 'classifier__gamma': 0.001, 'classifier__kernel': 'rbf'}, {'classifier__C': 10, 'classifier__gamma': 0.0001, 'classifier__kernel': 'rbf'}, {'classifier__C': 100, 'classifier__gamma': 0.001, 'classifier__kernel': 'rbf'}, {'classifier__C': 100, 'classifier__gamma': 0.0001, 'classifier__kernel': 'rbf'}, {'classifier__C': 1000, 'classifier__gamma': 0.001, 'classifier__kernel': 'rbf'}, {'classifier__C': 1000, 'classifier__gamma': 0.0001, 'classifier__kernel': 'rbf'}], 'split0_test_score': array([0.99098287, 0.98917944, 0.98917944, 0.98917944, 0.56898106,\n",
      "       0.56898106, 0.9657349 , 0.56898106, 0.9864743 , 0.9657349 ,\n",
      "       0.98917944, 0.9864743 ]), 'split1_test_score': array([0.98917944, 0.99008115, 0.99008115, 0.99008115, 0.56898106,\n",
      "       0.56898106, 0.97024346, 0.56898106, 0.98827773, 0.97024346,\n",
      "       0.99008115, 0.98827773]), 'split2_test_score': array([0.99549143, 0.99458972, 0.99458972, 0.99458972, 0.56898106,\n",
      "       0.56898106, 0.9792606 , 0.56898106, 0.99188458, 0.9792606 ,\n",
      "       0.99549143, 0.99188458]), 'split3_test_score': array([0.99368801, 0.99368801, 0.99368801, 0.99368801, 0.56807935,\n",
      "       0.56807935, 0.98016231, 0.56807935, 0.99188458, 0.98016231,\n",
      "       0.99368801, 0.99188458]), 'split4_test_score': array([0.99187726, 0.99187726, 0.99187726, 0.99187726, 0.56859206,\n",
      "       0.56859206, 0.97111913, 0.56859206, 0.98916968, 0.97111913,\n",
      "       0.99277978, 0.98916968]), 'mean_test_score': array([0.9922438 , 0.99188312, 0.99188312, 0.99188312, 0.56872292,\n",
      "       0.56872292, 0.97330408, 0.56872292, 0.98953817, 0.97330408,\n",
      "       0.99224396, 0.98953817]), 'std_test_score': array([0.00217933, 0.00205622, 0.00205622, 0.00205622, 0.00035531,\n",
      "       0.00035531, 0.00554886, 0.00035531, 0.00210348, 0.00554886,\n",
      "       0.00232325, 0.00210348]), 'rank_test_score': array([ 2,  3,  3,  3, 10, 10,  8, 10,  6,  8,  1,  6], dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "# Melatih model dengan grid search\n",
    "get_ipython().run_line_magic('time', 'classifier = grid_svm.fit(text_train, liked_train) # find the best combination from param_svm')\n",
    "print(classifier.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       584\n",
      "           1       1.00      0.99      0.99       803\n",
      "\n",
      "    accuracy                           0.99      1387\n",
      "   macro avg       0.99      0.99      0.99      1387\n",
      "weighted avg       0.99      0.99      0.99      1387\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mengevaluasi performa model pada data uji\n",
    "print(classification_report(liked_test, classifier.predict(text_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Contoh prediksi untuk kalimat positif\n",
    "print(classifier.predict([\"the vinci code is awesome\"])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Contoh prediksi untuk kalimat negatif\n",
    "print(classifier.predict([\"the vinci code is bad\"])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32465246735834974"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implementasi fungsi kernel Gaussian untuk SVM\n",
    "def gaussKernel(x1, x2, sigma):\n",
    "    ss = np.power(sigma, 2)\n",
    "    norm = (x1-x2).T.dot(x1-x2)\n",
    "    return np.exp(-norm/(2*ss))\n",
    "\n",
    "# Contoh penggunaan kernel Gaussian\n",
    "x1 = np.array([1, 2, 1])\n",
    "x2 = np.array([0, 4, -1])\n",
    "sigma = 2\n",
    "gaussKernel(x1, x2, sigma)  # Menghitung nilai kernel Gaussian antara dua vektor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main-ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
